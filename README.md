1.В данной программе описано распознавание неестественных поз человека с помощью Python3. Все действия выполнены на Ubuntu 20.04.5 LTS 
Данная программа на основе геометрического анализа кинематического изображения человека с хорошей точностью распознает такие положения как: поднятые руки (отдельно правая, отдельно левая, одновременно правая и левая), руки на голове и скрещенные на груди руки.

2.Необходимые компоненты - устройство, на котором будет запущен python3 код и видеокамера, с которой будет считываться изображение в режиме реального времени.

3.Установка OpenCV и MediaPipe.

OpenCV (Open Source Computer Vision Library) — это открытая библиотека для работы с алгоритмами компьютерного зрения, машинным обучением и обработкой изображений. 
Она нам необходима для считывания изображения и работы с ним в дальнейшем.
Для установки необходимо ввести в терминал: pip3 install opencv-python

MediaPipe — это фреймворк с открытым исходным кодом, представленный Google, который помогает создавать мультимодальные конвейеры машинного обучения. Эта структура может использоваться для различных приложений для обработки изображений и мультимедиа, таких как обнаружение объектов, распознавание лиц, отслеживание рук, распознавание тела человека. С помощью него будет отслеживаться кинематическая модель человека, с достаточно хорошими показателями точности.
Для установки необходимо ввести в терминал: pip3 install mediapipe

4.Запуск программы.
Для запуска программы необходимо через терминал перейти к директории с исполняемым файлом body_pose_estimation.py и ввести команду: python3 body_pose_estimation.py 

5.Объяснение программы распознавания неестественных поз человека. 
Разобьем программу на несколько этапов и подробно опишем каждый.

Этап 1.
Необходимо подключить предварительно установленные модули OpenCV и MediaPipe

    import cv2
    import mediapipe as mp

Этап 2.
    Подключение изображения в режиме реального времени (0 - порядковый номер камеры, вместо него можно указать mp3 файл, если имеется необходимость проверить работу программы на предварительно записанном видеоряде).
    А также, подключение из mediapipe таких компонент как: инструмент для рисования костей и суставов на выведенном видеоизображении, раздел для распознавания тела человека в кинематическом формате.
    И создание объектна класса "поза" из модуля mediapipe
    
    cam = cv2.VideoCapture(0)                           # подключаем изображение с камеры в режиме реального времени
    mpDraw = mp.solutions.drawing_utils                 # подключаем инструмент для рисования
    mp_pose = mp.solutions.pose                         # подключаем раздел распознавания тела
    pose = mp_pose.Pose()                               # объект класса "поза"

Этап 3.
Следующий этап программы подразумевает создание нескольких массивов для хранения и анализа полученной с изображения информации о положении определенных частей тела.
Вся нумерация отдельных точек (суставов) указана в файле Points.png 

    py = [0 for i in range(33)]                         #массив для хранения точек скелета по оси Y
    px = [0 for i in range(33)]                         #массив для хранения точек скелета по оси X

    hand_raised = [0 for i in range(2)]                 #индикатор поднятых рук
    hand_on_head = [0 for i in range(2)]                #индикатор рук на голове
    hand_on_shoulder = [0 for i in range(2)]            #индикатор рук на плечах (для перекрещенных рук)
    elbow_near_hip = [0 for i in range(2)]              #индикатор правильного положения локтей (для перекрещенных рук)

Этап 4.
Дальнейшие действия будут производиться в бесконечном цикле, для покадровой обработки изображения.

    while True:
        good, img = cam.read()                         #покадрово читаем изображение
        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #преобразуем в RGB
        results = pose.process(imgRGB)                 #получаем результат

Этап 5.
В следующем этапе выполняется проверка поступили ли с изображения точки (суставы), и в таком случае считываются координаты каждой точки в трехмерном пространстве. После чего на выходное изображение нарисуются линии (кости) для отображения связей.

        if results.pose_landmarks:                                      #если удалось распознать точки (суставы)
            for bodyLms in results.pose_landmarks.landmark:             #читаем координаты каждой точки
                mpDraw.draw_landmarks(img, results.pose_landmarks,      #Соединяем точки линиями
                                    mp_pose.POSE_CONNECTIONS)
Этап 6.
Все дальнешие действия будут производиться внутри цикла из прошлого этапа для каждой нужной нам точки.
Создаем список с коодинатами каждой точки скелета (если какая-то часть тела находится вне зоны видимости камеры, например, если камера видит человека выше пояса, то остальные координаты тоже заполняются, но принимают отрицательные значения). Далее необходимо получить размеры изображения и отмасштабировать их. Заполняем два массива с координатомы каждой точки по оси Y (вертикали) и оси X (горизонтали).

                for id, point in enumerate(results.pose_landmarks.landmark) :                           #создаем список с координатами точек
                    width, height, color = img.shape                                                    #получаем размеры изображения с камеры и масштабируем
                    width, height = int(point.x * height), int(point.y * width)

                    py[id] = height             #Заполняем массив координатами по оси Y
                    px[id] = width              #Заполняем массив координатами по оси X
Этап 7.
В данном этапе реализовано распознавание поднятых рук.
Необходимо получить допустимое расстояние по оси Y, с которым мы будем сравнивать расстояние между какой-либо точкой тела и кистью для заполнения индикаторов поднятой или опущенной руки.
В данном примере использовано расстоние от плеча до бедра (точки 12 и 24 (см. Points.png)), умноженное на коэффициент, удовлетворяющий необходимой точности.
После чего для каждой руки выполняется проверка: Находится ли необходимая рука (точка кисти) на достаточном расстоянии от соответствующего ей бедра.
В зависимости от полученных результатов для каждого кадра выведется сообщение о том, какая рука поднята или подняты обе.

                Good_distance_for_raised_hands = distance(py[12], py[24]) * 5/3     # получаем расстояние, с которым будем сравнивать каждую руку 
                                                                                #(берем расстояние от плеча до бедра и умножаем на кооэффициент, необходимый для заданной точности распознавания)       
                # 0 - правая, 1 - левая
                hand_raised[0] = 1 if distance(py[24], py[16]) > Good_distance_for_raised_hands else 0 #Распознаем, поднята ли правая рука
                hand_raised[1] = 1 if distance(py[23], py[15]) > Good_distance_for_raised_hands else 0 #Распознаем, поднята ли левая рука
                #Вывод сообщений на экран в зависимости от комбинаций поднятых рук
                if (hand_raised[0]) and (hand_raised[1]):
                    print("hands up")
                if (hand_raised[0]) and not (hand_raised[1]):
                    print("right hand raised")
                if not (hand_raised[0]) and (hand_raised[1]):
                print("left hand raised")

Этап 8. 
На данном этапе реализовано распознавание человека, который держит обе руки на голове.
По тому же принципу получаем допустимое расстояние по обеим осям, с которым будем сравнивать расстояние между точками кисти и различными точками лица.
Заполняем индикаторы для обеих рук и выводим на экран результат, если обе руки находятся на голове.

                # получаем расстояние, с которым будем сравнивать руки на голове по горизонтали и вертикали 
                Good_distance_for_hands_on_head_X = distance(px[8], px[7]) * 8/15 
                Good_distance_for_hands_on_head_Y = distance(py[6], py[9]) * 2
                #Распознаем руки на голове (0 - правая , 1 - левая)
                hand_on_head[0] = 1 if (distance(px[8], px[16]) < Good_distance_for_hands_on_head_X and distance(py[8], py[16]) < Good_distance_for_hands_on_head_Y) else 0
                hand_on_head[1] = 1 if (distance(px[7], px[15]) < Good_distance_for_hands_on_head_X and distance(py[7], py[15]) < Good_distance_for_hands_on_head_Y) else 0
                #если обе руки на голове, выводим сообщение
                if (hand_on_head[0]) and (hand_on_head[1]):
                    print("hands on head")
                
Этап 9. 
На данном этапе реализованно распознавание позы, в которой человек держит на груди перекрещенные руки.
По тому же принципу нам необходимо получить несколько допустимых расстояний, с которым мы будем сравнивать расстояние между точкой кисти и точкой противоположного плеча для каждой руки по обеим осям.
И Заполняем индикаторы, находятся ли руки на противоположных плечах. 
Далее необходимо проверить, находятся ли локти снизу, иначе если поместить кисти на противоположные плечи и задрать руки вверх, то программа выведет ошибочный результат.
Получаем необходимое расстояние, с которым будем сравнивать расстояние между каждой рукой и соответствующим ей бедром.
Заполняем индикаторы. Если обе руки находятся на противоположных плечах и оба локтя находятся на допустимом расстоянии к соответствующим им бедрам, выводим результат на экран с распознанной позой.

                #Получаем расстояние по осям X и Y для сравнения кистей на противоположных плечах
                Good_distance_for_cross_hands_X = (distance(px[12], px[11]) / 3)
                Good_distance_for_cross_hands_Y = (distance(px[12], px[11]) / 3)
                #Распознаем руки (0 - правая, 1 - левая) на противоположных плечах по обеим координатам
                hand_on_shoulder[0] = 1 if (distance(px[16], px[11]) < Good_distance_for_cross_hands_X and distance(py[16], py[11]) < Good_distance_for_cross_hands_Y)  else 0
                hand_on_shoulder[1] = 1 if (distance(px[15], px[12]) < Good_distance_for_cross_hands_X and distance(py[15], py[12]) < Good_distance_for_cross_hands_Y)  else 0
                #Получаем расстояние по оси Y для правильного положения локтя (рядом с соответствующим бедром)
                Good_distance_for_elbow_Y = distance(px[24], px[23]) * 3/2
                #Убеждаемся, что локти (0 - правый, 1 - левый) находятся рядом с соответствующими бедрами
                elbow_near_hip[0] = 1 if distance(py[14], py[24]) < Good_distance_for_elbow_Y else 0
                elbow_near_hip[1] = 1 if distance(py[13], py[23]) < Good_distance_for_elbow_Y else 0
                #Выводим на экран распознанные перекрещенные руки
                if (hand_on_shoulder[0] and hand_on_shoulder[1] and elbow_near_hip[0] and elbow_near_hip[1]):
                    print("CROSS")
                
Этап 10.
Данный этап является заключительным. Каждая строчка относится к бесконечному циклу.
Здесь мы выведем на экран наше преобразованное изображение для каждого кадра.
Для прерывания программы необходимо ввести символ "q", который прервет бесконечный цикл.

    cv2.imshow("Image", img)           # выводим окно с нашим изображением
    if cv2.waitKey(1) == ord('q'):     # ждем нажатия клавиши q в течение 1 мс для прерывания процесса
        break    
